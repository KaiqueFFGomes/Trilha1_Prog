Sistemas de inteligência artificial
Embora uma definição precisa e abrangente de inteligência artificial possa desempenhar um papel essencial em muitas questões jurídicas e éticas, não é particularmente necessária ou desejável para os fins deste artigo. A despeito disso, importante notar, a título de esclarecimento, que “inteligência artificial” é um termo que, desde sua concepção, nos anos 1950, pressupõe diferentes definições e abordagens, cada qual em seus diferentes contextos. Tais definições e abordagens, muitas vezes focadas na capacidade de emular uma ou outra capacidade humana, foram celebremente estruturadas por Russel e Norvig (2016, p. 2), que identificaram quatro pontos focais diferentes a partir dos quais se pode pensar em inteligência artificial. Especificamente, o termo pode referir-se a máquinas capazes de: (i) pensar como humanos; (ii) agir como humanos; (iii) pensar racionalmente ou (iv) agir racionalmente. Na esteira da possibilidade de “agir racionalmente”, elaboraram a hoje frequentemente utilizada definição de agente racional: “aquele que age de forma a alcançar o melhor resultado ou, quando há incerteza, o melhor resultado esperado” (Russel & Norvig, 2016, p. 2, tradução livre).

Trata-se, como se vê, de uma definição centrada na ideia de “resultado” e na possibilidade de alcançá-lo de uma forma ou de outra. No entanto, como bem apontado por Scherer (2015, p. 361), a dificuldade de se definir concretamente um sistema a partir de tais noções, em vista da amplitude de significados possíveis para “resultado” ou “melhor resultado esperado”, tem por corolário a dificuldade de fixação do termo em uma tecnologia objetivamente delimitada – e, por consequência, sua limitada aplicabilidade a questões regulatórias. Em verdade, conforme passamos a elucidar em seguida, buscamos nos focar para os fins deste artigo em um dos tipos específicos de inteligência artificial: os algoritmos de machine learning, ou aprendizado de máquina. Trata-se de vertente da inteligência artificial que, principalmente com o aumento na quantidade de bases de dados disponíveis e na capacidade computacional dos microchips de silício, viu impressionante desenvolvimento nos últimos anos (Alpaydin, 2016, p. 1).

Assim, no âmbito desta exposição, um “sistema de inteligência artificial” é definido como um software que possui capacidades de autoaprendizagem e pode, portanto, tomar decisões autônomas independentes. Como todo software, deve encontrar-se armazenado em algum hardware, importância do qual variará entre os diferentes sistemas de inteligência artificial (por exemplo, a importância do hardware para delimitar o que constitui um “carro autônomo” é maior do que para delimitar o que constitui um “assistente de voz”, tecnologia normalmente armazenada nos servidores da empresa que a disponibiliza). Com efeito, para muitos autores, é exatamente essa capacidade de “autoaprendizagem” o que caracteriza determinado sistema como imbuído de “inteligência artificial” (Čerka, Grigienėa & Sirbikytėb, 2015, p. 4; Scherer, 2015, p. 365; Calo, 2015, p. 538). Neste item, trataremos brevemente, portanto, dos dois aspectos trazidos por essa definição: (i) capacidade de autoaprendizagem e (ii) decisões autônomas ou independentes.

Como mencionado, as capacidades de autoaprendizagem são possibilitadas e delimitadas por técnicas que se enquadram no conceito de aprendizado de máquina. Trata-se, de maneira geral, de um processo que permite que um sistema aprenda novos fatos a partir de dados sem algoritmos explícitos, bem como adaptar tais fatos aprendidos a novas situações (Alpaydin, 2016, p. 17).

Algumas abordagens comuns à autoaprendizagem incluem os campos da aprendizagem em árvore de decisão, por regras de associação, redes bayesianas, aprendizagem de reforço, deep learning, entre outras (Čerka, Grigienėa & Sirbikytėb, 2015, p. 4; Alpaydin, 2016, p. 20; Ertel, 2013, pp. 203-226). Embora estas sejam frequentemente citadas como áreas específicas da inteligência artificial, elas não passam de processos diferentes para o que se apontou acima: em outras palavras, a percepção de padrões em dados para sua conformação em novos cenários, de forma a permitir conclusões não explicitamente buscadas por seus programadores. As diferentes técnicas mencionadas diferem em seus algoritmos e, principalmente, na forma como os dados são fornecidos e como novos resultados surgem a partir desses dados. A capacidade de autoaprendizagem, portanto, refere-se exatamente à possibilidade que tais sistemas têm de realizar tais inferências não esperadas e não pré-programadas a partir de um conjunto de dados.

Precisamente porque os sistemas de inteligência artificial não são integralmente limitados por regras humanas predeterminadas, eles podem encontrar soluções que as pessoas não haviam considerado, ou que, mesmo que pareçam a princípio menos intuitivas, são mais eficientes (e.g. do ponto de vista de gasto energético) para atingir os objetivos para o qual os sistemas em questão foram criados (Balkin, 2015, p. 52). É precisamente esta capacidade de criar soluções inesperadas que torna a utilização de sistemas de inteligência artificial cada vez mais atrativa numa variedade de áreas. Às soluções, ou ao “output” dos sistemas de inteligência artificial, por envolverem a escolha de determinada solução em detrimento de outras, e como forma de ressaltar seu caráter independente de algoritmos pré-determinados, damos o nome de “decisão”.

O fato central a se atentar aqui, assim, é que tais decisões não são diretamente decorrentes da programação original de seus desenvolvedores e são, portanto, até certo ponto, incontroláveis, como bem apontado por Scherer (2015, p. 366):

Pode ser difícil para os seres humanos manter o controle de máquinas que são programadas para agir com considerável autonomia. Há um grande número de formas pelas quais uma perda do controle pode ocorrer: um mau funcionamento, tal como um arquivo corrompido ou dano físico ao equipamento de input; uma brecha de segurança; o tempo de resposta superior dos computadores comparados aos seres humanos; ou programação defeituosa. Essa última possibilidade levanta os desafios mais interessantes, porque cria a possibilidade de que uma perda do controle pode ser consequência direta, mas involuntária, de uma escolha de design consciente. O controle, uma vez perdido, pode ser difícil de se recuperar se o sistema de IA for projetado com recursos que lhe permitam aprender e se adaptar. Estas são as características que fazem da IA uma potencial fonte de risco público numa escala que excede em muito as formas mais familiares de risco público que são apenas o resultado do comportamento humano. (Tradução livre)

Assim, por tais características, fala-se que as decisões tomadas por sistemas de inteligência artificial são independentes ou autônomas. Adiante, utilizaremos os termos “decisão autônoma” e “decisão independente” de forma intercambiável.

Por fim, é importante notar aqui que a capacidade de tomar decisões independentes e aprender com a própria experiência é justamente o que torna a inteligência artificial atrativa; não se trata meramente de característica inafastável de uma tecnologia qualquer, mas também sua própria vantagem frente a outras formas de solução de problemas.
